{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Join Key Finder Agent\n",
    "\n",
    "Purpose:  demonstrate a LangChain agent that can help us reverse\n",
    "engineer unfamiliar database tables--for example, ones that were\n",
    "recently imported into a company's data warehouse from a vendor, with\n",
    "minimal documentation.\n",
    "\n",
    "Amazon Q Developer was used to create the first draft of these functions.\n",
    "For more details, please see:\n",
    "https://github.com/zenbananas19/ai-for-data-modeling\n",
    "\n",
    "March 13, 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Useful libraries\n",
    "import os\n",
    "import sys\n",
    "import io\n",
    "import re\n",
    "import json\n",
    "import csv as csv\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "\n",
    "from langchain.tools import StructuredTool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "# Many LLM options are available.\n",
    "# For one of the agent's steps, let's try DeepSeek through Ollama.\n",
    "from langchain.llms import OpenAI\n",
    "from langchain_community.llms import Ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Database connection setup.  Please configure yours as appropriate.\n",
    "\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": \"a_company_database\",\n",
    "    \"user\": \"your_user_name\",\n",
    "    \"password\": f\"{secure_password}\",\n",
    "    \"host\": \"cloud data warehouse URL\",\n",
    "    \"port\": \"a port number\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING OLLAMA CONNECTION\n",
      "NAME               ID              SIZE      MODIFIED     \n",
      "deepseek-r1:14b    ea35dfe18182    9.0 GB    10 hours ago    \n",
      "deepseek-r1:8b     28f8fd6cdc67    4.9 GB    4 weeks ago     \n",
      "llama3:latest      365c0bd3c000    4.7 GB    6 months ago    \n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "LangChain is a framework designed to enable large language models (LLMs) such as OpenAI's GPT-3 to process and generate text in sequences. It allows for chaining multiple LLM operations, enabling tasks like text generation, summarization, question answering, and more complex reasoning processes.\n",
      "\n",
      "Key features of LangChain include:\n",
      "\n",
      "1. **Chaining Operations**: Enables the concatenation of multiple LLM responses or operations.\n",
      "2. **Context Management**: Maintains context across different steps of an operation.\n",
      "3. **Multi-Modal Support**: Can integrate text, images, audio, or other data types.\n",
      "4. **Flexibility**: Supports various use cases and customization through plugins.\n",
      "\n",
      "LangChain is particularly useful for tasks that require iterative reasoning or generation, such as creating stories, composing music, or conducting conversations where multiple steps are needed. It effectively leverages the power of LLMs by allowing them to build upon previous outputs, enhancing creativity and efficiency in generating coherent and contextually relevant text.\n"
     ]
    }
   ],
   "source": [
    "# -- See if ollama list shows a running instance\n",
    "print(\"TESTING OLLAMA CONNECTION\")\n",
    "!ollama list\n",
    "\n",
    "# Load the local model.  Both of these run fine on a Macbook Pro.\n",
    "# llm = Ollama(model=\"deepseek-r1:14b\")\n",
    "llm = Ollama(model=\"deepseek-r1:8b\")\n",
    "\n",
    "# Try a test prompt\n",
    "response = llm.invoke(\"What is LangChain?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Functions\n",
    "\n",
    "Each of these functions will become LangChain Agent tools, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Helper function to query our cloud data warehouse\n",
    "def execute_redshift_query(query: str):\n",
    "    \"\"\"Executes a SQL query on Redshift and returns the result as a DataFrame.\"\"\"\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    df = None\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(query)\n",
    "            colnames = [desc[0] for desc in cur.description]\n",
    "            rows = cur.fetchall()\n",
    "            df = pd.DataFrame(rows, columns=colnames)\n",
    "    finally:\n",
    "        conn.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Step 1 & 3: Pull up to 5000 random rows from a table\n",
    "def get_random_rows(table_name: str):\n",
    "    \"\"\"Fetches 5000 random rows from the specified database table.\"\"\"\n",
    "    query = f\"\"\"\n",
    "    SELECT * FROM {table_name}\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 5000;\n",
    "    \"\"\"\n",
    "    return execute_redshift_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Step 2 & 4: Analyze table and detect primary key candidates\n",
    "def analyze_primary_key(df: Dict[str, list]):\n",
    "    \"\"\"Identifies the most likely primary key based on cardinality, null counts, data types, and sample values.\"\"\"\n",
    "    df = pd.DataFrame(df)  # Convert dictionary to DataFrame\n",
    "    total_rows = len(df)\n",
    "    pk_characteristics = {}\n",
    "    \n",
    "    for column in df.columns:\n",
    "        unique_count = df[column].nunique()\n",
    "        null_count = df[column].isna().sum()\n",
    "        data_type = str(df[column].dtype)\n",
    "        sample_value = df[column].dropna().iloc[0] if null_count < total_rows else None\n",
    "        \n",
    "        # Probability is based on uniqueness and non-null values\n",
    "        pk_prob = 0.85 * ((unique_count / total_rows) * (1 - null_count / total_rows)) \\\n",
    "                    + 0.15 * ((\"id\" in column.lower()) | (\"tag\" in column.lower()))\n",
    "        \n",
    "        pk_characteristics[column] = {\n",
    "            \"probability\": round(pk_prob, 2),\n",
    "            \"data_type\": data_type,\n",
    "            \"sample_value\": sample_value\n",
    "        }\n",
    "    \n",
    "    return pk_characteristics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Step 5: Recommend join keys based on primary key analysis.\n",
    "# -- Note:  tune the weightings for your database column naming conventions.\n",
    " \n",
    "def recommend_join_keys(data: Dict[str, Dict[str, Dict]]):\n",
    "    \"\"\"Finds common primary key candidates across two tables using weighted conditions for probability, data types, and sample values.\"\"\"\n",
    "    pk_table1 = data[\"pk_table1\"]\n",
    "    pk_table2 = data[\"pk_table2\"]\n",
    "    key_scores = {}\n",
    "    \n",
    "    for col1, attr1 in pk_table1.items():\n",
    "        for col2, attr2 in pk_table2.items():\n",
    "            score = (\n",
    "                0.22 * (col1 == col2) +\n",
    "                0.22 * (attr1[\"probability\"] > 0.8) +\n",
    "                0.22 * (attr2[\"probability\"] > 0.8) +\n",
    "                0.22 * (attr1[\"data_type\"] == attr2[\"data_type\"]) +\n",
    "                0.16 * (attr1[\"sample_value\"] is not None and attr2[\"sample_value\"] is not None and len(str(attr1[\"sample_value\"])) == len(str(attr2[\"sample_value\"])))\n",
    "            )\n",
    "            best_col_score = max(key_scores.get(col1, {\"score\": 0})[\"score\"], score)\n",
    "            if best_col_score >= 0.5:\n",
    "                key_scores[col1] = {\n",
    "                    \"score\": max(key_scores.get(col1, {\"score\": 0})[\"score\"], score),\n",
    "                    \"table\": \"both\" if col1 in pk_table1 and col1 in pk_table2 else (\"table1\" if col1 in pk_table1 else \"table2\")\n",
    "                }\n",
    "    \n",
    "    sorted_keys = sorted(key_scores.items(), key=lambda x: x[1][\"score\"], reverse=True)\n",
    "    return {\"recommended_keys\": [{\"key\": key, \"score\": details[\"score\"], \"table\": details[\"table\"]} for key, details in sorted_keys]}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Step 6: Execute an inner join query\n",
    "# AgentType.ZERO_SHOT... requires a single argument, so we're making it a dictionary.\n",
    "def execute_join_query(data: Dict[str, str]):\n",
    "    \"\"\"Executes an inner join query on two tables using the specified join key.\"\"\"\n",
    "    table1 = data[\"table1\"]\n",
    "    table2 = data[\"table2\"]\n",
    "    join_key = data[\"join_key\"]\n",
    "    query = f\"\"\"\n",
    "    SELECT COUNT(*) AS match_count FROM {table1} t1\n",
    "    INNER JOIN {table2} t2 ON t1.{join_key} = t2.{join_key};\n",
    "    \"\"\"\n",
    "    return execute_redshift_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Step 7: Assess the join operation\n",
    "def assess_join_success(data: Dict[str, list]):\n",
    "    \"\"\"Analyzes the join success by calculating the match count and success rate.\"\"\"\n",
    "    df = pd.DataFrame(data[\"join_result\"])  # Convert dictionary to DataFrame\n",
    "    total_rows1 = data[\"total_rows1\"]\n",
    "    total_rows2 = data[\"total_rows2\"]\n",
    "    match_count = df.iloc[0, 0]\n",
    "    join_success_rate = match_count / min(total_rows1, total_rows2)\n",
    "    return {\"match_count\": match_count, \"join_success_rate\": round(join_success_rate, 2)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define LangChain Tools\n",
    "get_table1_tool = StructuredTool.from_function(get_random_rows, description=\"Fetches 5000 random rows from a specified table.\")\n",
    "get_table2_tool = StructuredTool.from_function(get_random_rows, description=\"Fetches 5000 random rows from a specified table.\")\n",
    "analyze_pk_tool = StructuredTool.from_function(analyze_primary_key, description=\"Analyzes a dictionary representing a DataFrame to determine primary key probabilities, data types, and sample values.\")\n",
    "recommend_keys_tool = StructuredTool.from_function(recommend_join_keys, description=\"Recommends the best columns to use as join keys between two tables, considering weighted probabilities, data types, and sample values.\")\n",
    "execute_join_tool = StructuredTool.from_function(execute_join_query, description=\"Executes an inner join query using a dictionary containing table names and a join key.\")\n",
    "assess_join_tool = StructuredTool.from_function(assess_join_success, description=\"Assesses the success of a join operation using a dictionary containing join results and row counts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Initialize LangChain Agent\n",
    "# One of llm = Ollama(model=\"deepseek-r1:8b\") or llm = Ollama(model=\"deepseek-r1:14b\") is defined at the top.\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=[get_table1_tool, get_table2_tool, analyze_pk_tool, recommend_keys_tool, execute_join_tool, assess_join_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    max_execution_time=150  # give it 150 seconds to run\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -- Example run (Replace 'table1' and 'table2' with actual table names)\n",
    "table1_df = get_random_rows(\"sample.orderinfo\")\n",
    "table2_df = get_random_rows(\"sample.skuinfo\")\n",
    "pk_table1 = analyze_primary_key(table1_df.to_dict(orient='list'))\n",
    "pk_table2 = analyze_primary_key(table2_df.to_dict(orient='list'))\n",
    "jk_args = {\"pk_table1\": pk_table1, \"pk_table2\": pk_table2}\n",
    "key_scores = recommend_join_keys(jk_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Please consider yourself a database administrator who is working on a data model for joining two unknown tables.\n",
    "First goal:  from the lists of foreign key candidates and their scores, please identify the best foreign keys to join the two tables.\n",
    "The JSON schema meanings are:\n",
    "'key' = the column name\n",
    "'score' = likelihood of being a good join key\n",
    "'table' = which of the two tables the column appears in.  If 'both', it appears in both tables.\n",
    "\n",
    "Please return a valid JSON object with the final answer, like this:\n",
    "{'Final Result': 'key name', 'Recommended Keys': [{'key': 'key name', 'score': 0.6, 'table': 'table1'}, ...]}\n",
    "\n",
    "\n",
    "Details:  the lists of columns for two database tables are provided.\n",
    "These columns were evaluated according to the following formula, implemented in Python, for their likelihood of being primary keys, and for potentially being foreign keys for joining to other tables.\n",
    "                0.22 * (column1 == column2) +\n",
    "                0.22 * (attr1[\"primary_key_probability\"] > 0.8) +\n",
    "                0.22 * (attr2[\"primary_key_probability\"] > 0.8) +\n",
    "                0.22 * (attr1[\"column_data_type\"] == attr2[\"column_data_type\"]) +\n",
    "                0.16 * (attr1[\"sample_value\"] is not None and attr2[\"sample_value\"] is not None and len(str(attr1[\"sample_value\"])) == len(str(attr2[\"sample_value\"])))\n",
    "\n",
    "The formula produces a score, where a high score close to 1.0 is more likely to be of value as a join key.\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Simple approach to capturing the output, as the verbose record of the LLM's thoughts and actions.\n",
    "# -- We expect the final output to be in a JSON at the bottom of the response text.\n",
    "\n",
    "# Redirect stdout to a string buffer\n",
    "captured_output = io.StringIO()\n",
    "sys.stdout = captured_output\n",
    "\n",
    "# Run your agent\n",
    "response_text = agent.invoke({\"input\": {\"prompt\": prompt, \"key_scores\": key_scores}})    #, tool=\"recommend_keys_tool\")\n",
    "\n",
    "# Restore stdout\n",
    "sys.stdout = sys.__stdout__\n",
    "\n",
    "# Get the captured output as a string\n",
    "verbose_output = captured_output.getvalue()\n",
    "\n",
    "verbose_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Entering new AgentExecutor chain...\n",
    "<think>\n",
    "Okay, so I'm trying to figure out how to best join two tables based on the information given. The prompt mentions that we're working with a database administrator's task, and the goal is to identify the best foreign keys for joining two unknown tables. \n",
    "\n",
    "First, let me parse through the details provided. There's a JSON schema mentioned where each key has attributes like 'key', 'score', and 'table'. The score is calculated using a formula that takes into account several factors:\n",
    "\n",
    "1. 0.22 * (column1 == column2): This checks if the columns are identical in both tables, which would be ideal for a join.\n",
    "2. 0.22 * (attr1[\"primary_key_probability\"] > 0.8) and similarly for attr2: This looks at whether each column has a high probability of being a primary key, which suggests they're unique and good candidates for joins.\n",
    "3. 0.22 * (data types match between the two columns): Same data type is important because you can't join different data types effectively.\n",
    "4. 0.16 * (sample values match in length): This ensures that the sample values from both tables are non-null and of the same length, which might indicate they're linked.\n",
    "\n",
    "The provided key_scores show a list of keys with their scores and which table(s) they belong to. The 'sku_id' key has the highest score at 0.82 and appears in both tables, which is great because it means it exists in both, making it more likely to be a good join key. \n",
    "\n",
    "So, considering the formula, 'sku_id' with such a high score should definitely be considered the best foreign key for joining. It satisfies multiple conditions: it's present in both tables, has a high primary key probability, and matches in data type and sample value length. Plus, it has a higher score than all other keys.\n",
    "\n",
    "I also notice that 'sku_id' is the only key with a score above 0.8, which makes it stand out. The next highest is 0.66, but those don't have as strong a presence in both tables or meet the high primary key probability threshold.\n",
    "\n",
    "Therefore, based on the analysis, 'sku_id' should be selected as the best foreign key to join these two tables.\n",
    "</think>\n",
    "\n",
    "To determine the best foreign keys for joining the two tables, we analyzed each candidate column using the provided formula. The 'sku_id' column emerged as the top choice due to its high score and presence in both tables.\n",
    "\n",
    "**Final Result:**\n",
    "{'Final Result': 'sku_id', 'Recommended Keys': [{'key': 'sku_id', 'score': 0.82, 'table': 'both'}]}\n",
    "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
    "Thought:<think>\n",
    "Alright, let me walk through how I arrived at the conclusion to use 'sku_id' as the best foreign key.\n",
    "\n",
    "1. **Understanding the Problem**: The task is to join two tables based on their columns. Each column has a score indicating its likelihood of being a good join key.\n",
    "\n",
    "2. **Analyzing Key Scores**: The 'planid' column has the highest score (0.82) and appears in both tables, which are strong indicators for a successful join.\n",
    "\n",
    "3. **Considering Formula Components**:\n",
    "   - The column is present in both tables.\n",
    "   - It has a high primary key probability.\n",
    "   - Data types match.\n",
    "   - Sample values are of equal length and non-null.\n",
    "\n",
    "4. **Conclusion**: 'sku_id' satisfies all the necessary conditions, making it the optimal choice for joining the two tables.\n",
    "\n",
    "**Final Answer:**\n",
    "{'Final Result': 'sku_id', 'Recommended Keys': [{'key': 'sku_id', 'score': 0.82, 'table': 'both'}]}\n",
    "\n",
    "> Finished chain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO:  extract the final answer from the response text, and test its recommended join key in steps 6 and 7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
